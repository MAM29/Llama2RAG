{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find torch installation command for your machine at https://pytorch.org/get-started/locally/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install langchain einops accelerate transformers bitsandbytes scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install xformers sentencepiece "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install llama-index==0.7.21 llama_hub==0.0.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install llama-index --upgrade --no-cache-dir --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install llama-index-llms-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install llama-index-embeddings-langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install -U llama-index-readers-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install text_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install lark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install llama-index-vector-stores-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import transformer classes for generaiton\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer\n",
    "# Import torch for datatype attributes \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variable to hold llama2 weights naming \n",
    "name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "# Set auth token variable from hugging face \n",
    "auth_token = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:711: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(name, \n",
    "    cache_dir='./model/', use_auth_token=auth_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\auto\\auto_factory.py:472: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53dbe46875f4f6388fb035e3922862d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create model\n",
    "model = AutoModelForCausalLM.from_pretrained(name, \n",
    "    cache_dir='./model/', use_auth_token=auth_token, torch_dtype=torch.float16, \n",
    "    rope_scaling={\"type\": \"dynamic\", \"factor\": 2}, load_in_8bit=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the prompt wrapper...but for llama index\n",
    "from llama_index.core.prompts.prompts import SimpleInputPrompt\n",
    "# Create a system prompt \n",
    "system_prompt = \"\"\"<s>[INST] <<SYS>>\n",
    "\n",
    " You are now a carbon footprint analyst. Your job is to reason about the carbon footprint of \"{product_name}\" \n",
    " based off its components. For each part of the calculation, explain how you came to that conclusion. Only use \n",
    " factual data for your computations and do not make assumptions. Do not use information about any other product\n",
    " other than \"{product_name}\" to perform your computations. If you cannot compute the carbon footprint \n",
    " from known information, return \"None\".<</SYS>>\n",
    "\"\"\"\n",
    "# Throw together the query wrapper\n",
    "query_wrapper_prompt = SimpleInputPrompt(\"{query_str} [/INST]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello [/INST]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Complete the query prompt\n",
    "query_wrapper_prompt.format(query_str='hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the llama index HF Wrapper\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "# Create a HF LLM using the llama index wrapper \n",
    "llm = HuggingFaceLLM(context_window=4096,\n",
    "                    max_new_tokens=1024,\n",
    "                    system_prompt=system_prompt,\n",
    "                    query_wrapper_prompt=query_wrapper_prompt,\n",
    "                    model=model,\n",
    "                    tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in embeddings wrapper\n",
    "from llama_index.embeddings.langchain import LangchainEmbedding\n",
    "# Bring in HF embeddings - need these to represent document chunks\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and dl embeddings instance  \n",
    "embeddings=LangchainEmbedding(\n",
    "    HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in stuff to change settings\n",
    "from llama_index.core import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish llama_index model settings\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embeddings\n",
    "Settings.chunk_size=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael\\AppData\\Roaming\\Python\\Python312\\site-packages\\onnxruntime\\capi\\onnxruntime_validation.py:26: UserWarning: Unsupported Windows version (11). ONNX Runtime supports Windows 10 and above, only.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import deps to load documents \n",
    "from llama_index.core import VectorStoreIndex, download_loader\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.chains import RetrievalQA\n",
    "from llama_index.core import Document\n",
    "\n",
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "import chromadb\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from llama_index.core import StorageContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User: Latitude 3470\n"
     ]
    }
   ],
   "source": [
    "# prompt user to enter question\n",
    "user_question = input(\"User:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store csv data into SQL database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.llamaindex.ai/en/stable/examples/index_structs/struct_indices/SQLIndexDemo/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Database Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    "    select,\n",
    "    Float,\n",
    ")\n",
    "from llama_index.core import SQLDatabase\n",
    "\n",
    "engine = create_engine(\"sqlite:///:memory:\")\n",
    "metadata_obj = MetaData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create city SQL table\n",
    "table_name = \"device_specs\"\n",
    "device_specs_table = Table(\n",
    "    table_name,\n",
    "    metadata_obj,\n",
    "    Column(\"Carbon Filename\", String(16)),\n",
    "    Column(\"Company\", String(16)),\n",
    "    Column(\"Device\", String(16)),\n",
    "    Column(\"Commercial_Name\", String(16), primary_key=True),\n",
    "    Column(\"PCF\", Integer),\n",
    "    Column(\"Manufacturing %\", Float),\n",
    "    Column(\"Chassis & Assembly %\", Float),\n",
    "    Column(\"Hard Drive %\", Float),\n",
    "    Column(\"SSD %\", Float),\n",
    "    Column(\"Power Supply %\", Float),\n",
    "    Column(\"Battery %\", Float),\n",
    "    Column(\"Mainboard and Other Boards %\", Float),\n",
    "    Column(\"Display %\", Float),\n",
    "    Column(\"Packaging %\", Float),\n",
    "    Column(\"Manufacturing Emissions\", Float),\n",
    "    Column(\"Chassis & Assembly Emissions\", Float),\n",
    "    Column(\"Hard Drive Emissions\", Float),\n",
    "    Column(\"SSD Emissions\", Float),\n",
    "    Column(\"Power Supply Emissions\", Float),\n",
    "    Column(\"Battery Emissions\", Float),\n",
    "    Column(\"Mainboard and Other Boards Emissions\", Float),\n",
    "    Column(\"Display Emissions\", Float),\n",
    "    Column(\"Packaging Emissions\", Float),\n",
    "    Column(\"Other Emissions\", Float),\n",
    "    Column(\"Specs Filename\", String(16)),\n",
    "    Column(\"Category\", String(16)),\n",
    "    Column(\"Processor Cores\", Float),\n",
    "    Column(\"RAM\", Float),\n",
    "    Column(\"SSD\", Float),\n",
    "    Column(\"HDD\", Float),\n",
    "    Column(\"Power\", Float),\n",
    "    Column(\"Display\", Float),\n",
    "    Column(\"Weight\", Float)\n",
    ")\n",
    "metadata_obj.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add csv to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import insert\n",
    "import pandas as pd\n",
    "\n",
    "sql_database = SQLDatabase(engine, include_tables=[table_name])\n",
    "\n",
    "df = pd.read_csv('./data/Combined_Dataset_Final.csv')\n",
    "\n",
    "# Convert the DataFrame into a list of dictionaries\n",
    "rows = df.to_dict('records')\n",
    "\n",
    "# Add csv to SQL database\n",
    "for row in rows:\n",
    "    stmt = insert(device_specs_table).values(**row)\n",
    "    with engine.begin() as connection:\n",
    "        cursor = connection.execute(stmt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View database items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Dell', 'Laptop', 'Latitude 3150', 216), ('Dell', 'Laptop', 'Latitude 3160', 244), ('Dell', 'Laptop', 'Latitude 3180', 243), ('Dell', 'Laptop', 'Latitude 3190', 226), ('Dell', 'Laptop', 'Latitude 3189', 257), ('Dell', 'Laptop', 'Latitude 3190 2-in-1', 230), ('Dell', 'Laptop', 'Latitude 3350', 258), ('Dell', 'Laptop', 'Latitude 3380', 252), ('Dell', 'Laptop', 'Latitude 3460', 279), ('Dell', 'Laptop', 'Latitude 3470', 286), ('Dell', 'Laptop', 'Latitude 3480', 324), ('Dell', 'Laptop', 'Latitude 3490', 243), ('Dell', 'Laptop', 'Latitude 3550', 263), ('Dell', 'Laptop', 'Latitude 3560', 298), ('Dell', 'Laptop', 'Latitude 3570', 302), ('Dell', 'Laptop', 'Latitude 3580', 311), ('Dell', 'Laptop', 'Latitude 3590', 254), ('Dell', 'Laptop', 'Latitude 5285 2-in-1', 258), ('Dell', 'Laptop', 'Latitude 5289 2-in-1', 259), ('Dell', 'Laptop', 'Latitude 5290', 218), ('Dell', 'Laptop', 'Latitude 5290 2-in-1', 268), ('Dell', 'Laptop', 'Latitude 5450', 247), ('Dell', 'Laptop', 'Latitude 5480', 250), ('Dell', 'Laptop', 'Latitude 5490', 251), ('Dell', 'Laptop', 'Latitude 5491', 254), ('Dell', 'Laptop', 'Latitude 5495', 255), ('Dell', 'Laptop', 'Latitude 5550', 259), ('Dell', 'Laptop', 'Latitude 5580', 299), ('Dell', 'Laptop', 'Latitude 5590', 271), ('Dell', 'Laptop', 'Latitude 5591', 305), ('Dell', 'Laptop', 'Latitude 7280', 222), ('Dell', 'Laptop', 'Latitude 7290', 209), ('Dell', 'Laptop', 'Latitude 7350', 297), ('Dell', 'Laptop', 'Latitude 7370', 288), ('Dell', 'Laptop', 'Latitude 7380', 259), ('Dell', 'Laptop', 'Latitude 7389 2-in-1', 289), ('Dell', 'Laptop', 'Latitude 7390', 222), ('Dell', 'Laptop', 'Latitude 7390 2-in-1', 332), ('Dell', 'Laptop', 'Latitude 7480', 249), ('Dell', 'Laptop', 'Latitude 7490', 241), ('Dell', 'Laptop', 'XPS 9570', 324), ('Dell', 'Laptop', 'XPS 9360', 286), ('Dell', 'Laptop', 'XPS 9365 2-in-1', 287), ('Dell', 'Laptop', 'XPS 9370', 297), ('Dell', 'Laptop', 'XPS 9560', 337), ('Dell', 'Laptop', 'Chromebook 3100', 266), ('Dell', 'Laptop', 'Chromebook 3100 2-in-1', 291), ('Dell', 'Laptop', 'Chromebook 3400', 335), ('Dell', 'Laptop', 'Chromebook 5190 2-in-1', 219), ('Dell', 'Laptop', 'Chromebook 5190', 220), ('Dell', 'Laptop', 'Chromebook 3110 2-in-1', 238), ('Dell', 'Laptop', 'Chromebook 3110', 229), ('Dell', 'Laptop', 'Inspiron 5320', 326), ('Dell', 'Laptop', 'Inspiron 5330', 328), ('Dell', 'Laptop', 'Inspiron 5420', 344), ('Dell', 'Laptop', 'Inspiron 5425', 345), ('Dell', 'Laptop', 'Inspiron 5430', 295), ('Dell', 'Laptop', 'Inspiron 7420 2-in-1', 366), ('Dell', 'Laptop', 'Inspiron 7425 2-in-1', 355), ('Dell', 'Laptop', 'Inspiron 7430 2-in-1', 304), ('Dell', 'Laptop', 'Inspiron Plus 7420', 376), ('Dell', 'Laptop', 'Inspiron Plus 7430', 345), ('Dell', 'Laptop', 'Inspiron 3530', 288), ('Dell', 'Laptop', 'Inspiron 5620', 386), ('Dell', 'Laptop', 'Inspiron 5625', 381), ('Dell', 'Laptop', 'Inspiron 5630', 373), ('Dell', 'Laptop', 'Inspiron 7620 2-in-1', 403), ('Dell', 'Laptop', 'Inspiron 7630 2-in-1', 396), ('Dell', 'Laptop', 'Inspiron Plus 7630', 420), ('Dell', 'Laptop', 'Latitude 3140 2-in-1', 254), ('Dell', 'Laptop', 'Latitude 3140', 251), ('Dell', 'Laptop', 'Latitude 3330 2-in-1', 311), ('Dell', 'Laptop', 'Latitude 3330', 313), ('Dell', 'Laptop', 'Latitude 3430', 298), ('Dell', 'Laptop', 'Latitude 3440', 312), ('Dell', 'Laptop', 'Latitude Chromebook 3445', 248), ('Dell', 'Laptop', 'Latitude 3530', 317), ('Dell', 'Laptop', 'Latitude 3540', 316), ('Dell', 'Laptop', 'Latitude 5330 2-in-1', 343), ('Dell', 'Laptop', 'Latitude 5330', 341), ('Dell', 'Laptop', 'Latitude 5340 2-in-1', 322), ('Dell', 'Laptop', 'Latitude 5340', 321), ('Dell', 'Laptop', 'Latitude Chromebook 5430', 329), ('Dell', 'Laptop', 'Latitude 5430', 301), ('Dell', 'Laptop', 'Latitude 5431', 298), ('Dell', 'Laptop', 'Latitude 5440', 290), ('Dell', 'Laptop', 'Latitude 5540', 321), ('Dell', 'Laptop', 'Latitude 7330 2-in-1', 296), ('Dell', 'Laptop', 'Latitude 7330', 277), ('Dell', 'Laptop', 'Latitude 7340', 340), ('Dell', 'Laptop', 'Latitude 7430 2-in-1', 359), ('Dell', 'Laptop', 'Latitude 7430', 286), ('Dell', 'Laptop', 'Latitude 7440 2-in-1', 355), ('Dell', 'Laptop', 'Latitude 7440', 285), ('Dell', 'Laptop', 'Latitude 7530', 314), ('Dell', 'Laptop', 'Latitude 7640', 349), ('Dell', 'Laptop', 'Latitude 9430 2-in-1', 380), ('Dell', 'Laptop', 'Latitude 9430', 375), ('Dell', 'Laptop', 'Latitude 9440 2-in-1', 391), ('Dell', 'Laptop', 'Vostro 3430', 268), ('Dell', 'Laptop', 'Vostro 3510', 273), ('Dell', 'Laptop', 'Vostro 3515', 282), ('Dell', 'Laptop', 'Vostro 3530', 296), ('Dell', 'Laptop', 'Vostro 5635', 383), ('Dell', 'Laptop', 'Vostro 5320', 326), ('Dell', 'Laptop', 'Vostro 5620', 386), ('Dell', 'Laptop', 'Vostro 5625', 380), ('Dell', 'Laptop', 'Vostro 7620', 412), ('Dell', 'Laptop', 'XPS 9520', 431), ('Dell', 'Laptop', 'XPS 9530', 435), ('Dell', 'Laptop', 'XPS 9730', 555), ('Dell', 'Desktop', 'XPS 8960', 498), ('Dell', 'Laptop', 'XPS 9315 2-in-1', 411), ('Dell', 'Laptop', 'XPS 9315', 404), ('Dell', 'Laptop', 'XPS 9320', 380), ('Dell', 'Laptop', 'XPS 9720', 524), ('Dell', 'Laptop', 'Latitude 3120 2-in-1', 245), ('Dell', 'Laptop', 'Latitude 3120', 231), ('Dell', 'Laptop', 'Latitude 3300', 293), ('Dell', 'Laptop', 'Latitude 3301', 317), ('Dell', 'Laptop', 'Latitude 3310 2-in-1', 334), ('Dell', 'Laptop', 'Latitude 3310', 283), ('Dell', 'Laptop', 'Latitude 3320', 281), ('Dell', 'Laptop', 'Latitude 3400', 279), ('Dell', 'Laptop', 'Latitude 3410', 322), ('Dell', 'Laptop', 'Latitude 3420', 315), ('Dell', 'Laptop', 'Latitude 3500', 278), ('Dell', 'Laptop', 'Latitude 3510', 340), ('Dell', 'Laptop', 'Latitude 3520', 318), ('Dell', 'Laptop', 'Latitude 5300', 296), ('Dell', 'Laptop', 'Latitude 5300 2-in-1', 316), ('Dell', 'Laptop', 'Latitude Chromebook 5300 2-in-1', 299), ('Dell', 'Laptop', 'Latitude 5310 2-in-1', 299), ('Dell', 'Laptop', 'Latitude 5310', 300), ('Dell', 'Laptop', 'Latitude 5320', 348), ('Dell', 'Laptop', 'Latitude 5320 2-in-1', 308), ('Dell', 'Laptop', 'Latitude 5400', 315), ('Dell', 'Laptop', 'Latitude Chromebook 5400', 325), ('Dell', 'Laptop', 'Latitude 5401', 344), ('Dell', 'Laptop', 'Latitude 5410', 326), ('Dell', 'Laptop', 'Latitude 5411', 333), ('Dell', 'Laptop', 'Latitude 5420', 364), ('Dell', 'Laptop', 'Latitude 5421', 304), ('Dell', 'Laptop', 'Latitude 5500', 393), ('Dell', 'Laptop', 'Latitude 5501', 403), ('Dell', 'Laptop', 'Latitude 5510', 348), ('Dell', 'Laptop', 'Latitude 5511', 378), ('Dell', 'Laptop', 'Latitude 5520', 324), ('Dell', 'Laptop', 'Latitude 5521', 379), ('Dell', 'Laptop', 'Latitude 5530', 364), ('Dell', 'Laptop', 'Latitude 5531', 373), ('Dell', 'Laptop', 'Latitude 7200 2-in-1', 314), ('Dell', 'Laptop', 'Latitude 7210 2-in-1', 305), ('Dell', 'Laptop', 'Latitude 7300', 323), ('Dell', 'Laptop', 'Latitude 7310', 328), ('Dell', 'Laptop', 'Latitude 7310 2-in-1', 326), ('Dell', 'Laptop', 'Latitude 7320', 336), ('Dell', 'Laptop', 'Latitude 7320 2-in-1', 333), ('Dell', 'Laptop', 'Latitude 7320 Detachable', 82), ('Dell', 'Laptop', 'Latitude 7400', 320), ('Dell', 'Laptop', 'Latitude 7400 2-in-1', 351), ('Dell', 'Laptop', 'Latitude 7410', 329), ('Dell', 'Laptop', 'Latitude 7410 2-in-1', 338), ('Dell', 'Laptop', 'Latitude 7420', 341), ('Dell', 'Laptop', 'Latitude 7420 2-in-1', 353), ('Dell', 'Laptop', 'Latitude 7520', 364), ('Dell', 'Laptop', 'Latitude 9410', 356), ('Dell', 'Laptop', 'Latitude 9420 2-in-1', 350), ('Dell', 'Laptop', 'Latitude 9420', 344), ('Dell', 'Laptop', 'Latitude 9510', 482), ('Dell', 'Laptop', 'Latitude 9520 2-in-1', 361), ('Dell', 'Laptop', 'Latitude 9520', 367), ('Dell', 'Laptop', 'Vostro 3435', 263), ('Dell', 'Laptop', 'Vostro 3535', 296), ('Dell', 'Laptop', 'XPS 9300', 327), ('Dell', 'Laptop', 'XPS 9310', 322), ('Dell', 'Laptop', 'XPS 9310 2-in-1', 342), ('Dell', 'Laptop', 'XPS 9380', 317), ('Dell', 'Laptop', 'XPS 9500', 380), ('Dell', 'Laptop', 'XPS 9510', 431), ('Dell', 'Laptop', 'XPS 9710', 509), ('Dell', 'Laptop', 'XPS 7390', 320)]\n"
     ]
    }
   ],
   "source": [
    "# view current table\n",
    "stmt = select(\n",
    "    device_specs_table.c.Company,\n",
    "    device_specs_table.c.Device,\n",
    "    device_specs_table.c[\"Commercial_Name\"],\n",
    "    device_specs_table.c.PCF,\n",
    ").select_from(device_specs_table)\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    results = connection.execute(stmt).fetchall()\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Dell_Carbon\\\\carbon-footprint-latitude-3470.pdf', 'Dell', 'Laptop', 'Latitude 3470', 286, 78.8, 4.9, 3.2, 0.0, 7.3, 2.8, 28.1, 33.1, 0.4, 225.368, 11.043032, 7.211776, 0.0, 16.451864, 6.310304, 63.328408, 74.596808, 0.901472, 45.524336, 'latitude-3470-laptop_owners-manual_en-us.pdf', 'Laptop', 4.0, 16.0, 2000.0, 2000.0, 90.0, 14.0, 1.81)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "# Surround user_question with quotes and add wildcard character % for partial matching\n",
    "search_term = f\"'%{user_question}%'\"\n",
    "\n",
    "# Use text() to create a SQL expression\n",
    "sql_query = text(f\"SELECT * FROM device_specs WHERE `Commercial_Name` LIKE {search_term}\")\n",
    "\n",
    "# Execute the query\n",
    "with engine.connect() as con:\n",
    "    rows = con.execute(sql_query)\n",
    "    for row in rows:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import NLSQLTableQueryEngine\n",
    "from llama_index.core.retrievers import NLSQLRetriever\n",
    "\n",
    "# default retrieval (return_raw=False)\n",
    "nl_sql_retriever = NLSQLRetriever(\n",
    "    sql_database, tables=[table_name], return_raw=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from llama_index.core.response.notebook_utils import display_source_node\n",
    "\n",
    "#results = nl_sql_retriever.retrieve(\n",
    "#    user_question\n",
    "#)\n",
    "\n",
    "# NOTE: all the content is in the metadata\n",
    "#for n in results:\n",
    "#    display_source_node(n, show_source_metadata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\llama\\modeling_llama.py:728: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the provided information, I have calculated the carbon footprint of the Dell Latitude 3470 laptop as follows:\n",
      "\n",
      "1. Manufacturing Emissions:\n",
      "The carbon footprint of the manufacturing process of the Latitude 3470 is 225.368 tons of CO2 equivalent (tCO2e). This is calculated by multiplying the percentage of the manufacturing process (78.8%) by the total manufacturing emissions (225.368 tCO2e).\n",
      "2. Chassis & Assembly Emissions:\n",
      "The carbon footprint of the chassis and assembly process of the Latitude 3470 is 11.043032 tCO2e. This is calculated by multiplying the percentage of the chassis and assembly process (4.9%) by the total chassis and assembly emissions (225.368 tCO2e).\n",
      "3. Hard Drive Emissions:\n",
      "The carbon footprint of the hard drive of the Latitude 3470 is 7.211776 tCO2e. This is calculated by multiplying the percentage of the hard drive (3.2%) by the total hard drive emissions (2000.0 tCO2e).\n",
      "4. SSD Emissions:\n",
      "Since the Latitude 3470 does not use any SSDs, the carbon footprint of SSDs is assumed to be zero (0.0 tCO2e).\n",
      "5. Power Supply Emissions:\n",
      "The carbon footprint of the power supply of the Latitude 3470 is 16.451864 tCO2e. This is calculated by multiplying the percentage of the power supply process (7.3%) by the total power supply emissions (2000.0 tCO2e).\n",
      "6. Battery Emissions:\n",
      "The carbon footprint of the battery of the Latitude 3470 is 6.310304 tCO2e. This is calculated by multiplying the percentage of the battery process (2.8%) by the total battery emissions (2000.0 tCO2e).\n",
      "7. Mainboard and Other Boards Emissions:\n",
      "The carbon footprint of the mainboard and other boards of the Latitude 3470 is 63.328408 tCO2e. This is calculated by multiplying the percentage of the mainboard and other boards process (28.1%) by the total mainboard and other boards emissions (2000.0 tCO2e).\n",
      "8. Display Emissions:\n",
      "The carbon footprint of the display of the Latitude 3470 is 74.596808 tCO2e. This is calculated by multiplying the percentage of the display process (33.1%) by the total display emissions (2000.0 tCO2e).\n",
      "9. Packaging Emissions:\n",
      "The carbon footprint of the packaging of the Latitude 3470 is 0.901472 tCO2e. This is calculated by multiplying the percentage of the packaging process (0.4%) by the total packaging emissions (2000.0 tCO2e).\n",
      "10. Other Emissions:\n",
      "The carbon footprint of the other components of the Latitude 3470 (such as cables, adapters, and other accessories) is 45.524336 tCO2e. This is calculated by adding the total emissions of all other components (45.524336 tCO2e) to the total emissions of the Latitude 3470 (2000.0 tCO2e).\n",
      "\n",
      "Therefore, the total carbon footprint of the Dell Latitude 3470 laptop is 2079.8 tCO2e.\n",
      "\n",
      "Note: The above calculations are based on the information provided in the Carbon Filename and Specs Filename, and do not take into account any additional emissions that may occur during the use and disposal of the laptop."
     ]
    }
   ],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "query_engine = RetrieverQueryEngine.from_args(nl_sql_retriever, streaming=True)\n",
    "\n",
    "response = query_engine.query(\n",
    "    user_question\n",
    ")\n",
    "response.print_response_stream()\n",
    "\n",
    "#print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
